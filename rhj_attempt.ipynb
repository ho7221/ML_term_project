{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 의문\n",
    "feature는 경기 결과의 일부인데 이걸로 점수를 예측하는 것이 경기 결과 예측이라고 할 수 있는지?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main idea\n",
    "1. Extract winning team's features\n",
    "2. Learn features with LinearRegression \n",
    "3. Test each teams' result and find which team is more similar to learned features\n",
    "4. predict which team will win"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import library & Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy pandas seaborn scikit-learn seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_SRC='./Data/Trainset/Trainset.csv'\n",
    "TEST_DATA_SRC='./Data/Testset/Testset.csv'\n",
    "train_df=pd.read_csv(TRAIN_DATA_SRC)\n",
    "test_df=pd.read_csv(TEST_DATA_SRC)\n",
    "\n",
    "features=['Possesion','Shots_on_target','Shots','Touches','Passes','Tackles','Clearance','Corners','Offsides','Yellow_cards','Fouls_conceded','Red_cards']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess trainset & testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_features=[features for features in list(train_df) if 'home' in features and 'team' not in features and 'Score' not in features]\n",
    "away_features=[features for features in list(train_df) if 'away' in features and 'team' not in features and 'Score' not in features]\n",
    "\n",
    "winning_train_df=pd.DataFrame(columns=features)\n",
    "losing_train_df=pd.DataFrame(columns=features)\n",
    "winning_test_df=pd.DataFrame(columns=features)\n",
    "losing_test_df=pd.DataFrame(columns=features)\n",
    "\n",
    "for i,row in train_df.iterrows():\n",
    "    if row[3]>row[4]:\n",
    "        winning_train_df.loc[i]=list(row[home_features])\n",
    "        losing_train_df.loc[i]=list(row[away_features])\n",
    "    elif row[4]>row[3]:\n",
    "        winning_train_df.loc[i]=list(row[away_features])\n",
    "        losing_train_df.loc[i]=list(row[home_features])\n",
    "\n",
    "for i,row in test_df.iterrows():\n",
    "    if row[3]>row[4]:\n",
    "        winning_test_df.loc[i]=list(row[home_features])\n",
    "        losing_test_df.loc[i]=list(row[away_features])\n",
    "    elif row[4]>row[3]:\n",
    "        winning_test_df.loc[i]=list(row[away_features])\n",
    "        losing_test_df.loc[i]=list(row[home_features])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.05861052 1.35979163 1.19311343 1.07502493 0.97270886 0.9155342\n",
      " 0.74296156 0.68236642 0.60193765 0.26418056 0.11750118]\n"
     ]
    }
   ],
   "source": [
    "pca=PCA(n_components='mle')\n",
    "scaler=StandardScaler()\n",
    "standardized_winning_train_df=pd.DataFrame(scaler.fit_transform(winning_train_df),columns=features)\n",
    "pca_winning_train_df=pca.fit_transform(standardized_winning_train_df)\n",
    "pov=pca.explained_variance_\n",
    "print(pov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8609793710708921\n"
     ]
    }
   ],
   "source": [
    "print(sum(pov[:7])/sum(pov))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_components가 앞 6개의 feature까지는 설명력이 .9 이상이지만 7번째부터 확연히 줄어들기 때문에 PoV가 .86이더라도 feature를 줄이는 것이 나을 것이라고 판단. \n",
    "n_components는 6으로 진행."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca=PCA(n_components=6)\n",
    "pca_winning_train_df=pd.DataFrame(pca.fit_transform(standardized_winning_train_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "근데 어떤 feature가 설명력이 높은지 알아야 앞으로 test에서 사용할 수 있음.\n",
    "아니면 testset을 2007-2022 data를 전부 합쳐서 pca를 진행하고 split_train_test 함수로 쪼개야함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train_df.drop(columns=['MatchID','Home_team','Away_team','Score_home','Score_away']).values\n",
    "y_train=train_df['Score_home'].values\n",
    "\n",
    "X_test=test_df.drop(columns=['MatchID','Home_team','Away_team','Score_home','Score_away']).values\n",
    "y_test=test_df['Score_home'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  1.0118445646471799\n",
      "Test RMSE:  0.9969077726364963\n",
      "Train Score:  0.4034846930488767\n",
      "Test Score:  0.43319843922805756\n"
     ]
    }
   ],
   "source": [
    "lin_reg=LinearRegression()\n",
    "lin_reg.fit(X_train,y_train)\n",
    "predictions=lin_reg.predict(X_test)\n",
    "Y_train_pred=lin_reg.predict(X_train)\n",
    "print(\"Train RMSE: \",np.sqrt(mean_squared_error(y_train,Y_train_pred)))\n",
    "print(\"Test RMSE: \",np.sqrt(mean_squared_error(y_test,predictions)))\n",
    "print(\"Train Score: \",r2_score(y_train,Y_train_pred))\n",
    "print(\"Test Score: \",r2_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6n/txlp40p947xbl8xqx_cmg3cr0000gn/T/ipykernel_46576/3888980993.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlog_reg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlog_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlin_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mY_train_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlin_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train RMSE: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "log_reg=LogisticRegression()\n",
    "log_reg.fit(X_train,y_train)\n",
    "predictions=lin_reg.predict(X_test)\n",
    "Y_train_pred=lin_reg.predict(X_train)\n",
    "print(\"Train RMSE: \",np.sqrt(mean_squared_error(y_train,Y_train_pred)))\n",
    "print(\"Test RMSE: \",np.sqrt(mean_squared_error(y_test,predictions)))\n",
    "print(\"Train Score: \",r2_score(y_train,Y_train_pred))\n",
    "print(\"Test Score: \",r2_score(y_test,predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem\n",
    "Dataset이 늘어나서 RMSE가 1이하로 내려갔지만 여전히 큼...  \n",
    "근데 문제점은 Train score가 Test score보다 낮음... 왜...?  \n",
    "Dataset을 수정하거나 feature를 추가하던가 해야될듯...\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e774977668b7c0ae8309835a5187aa7fbf7669e7d0bb59755bc63e573643edcd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
