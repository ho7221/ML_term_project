{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 의문\n",
    "feature는 경기 결과의 일부인데 이걸로 점수를 예측하는 것이 경기 결과 예측이라고 할 수 있는지?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main idea\n",
    "1. Extract winning team's features\n",
    "2. Learn features with LinearRegression \n",
    "3. Test each teams' result and find which team is more similar to learned features\n",
    "4. predict which team will win"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import library & Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (1.21.6)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (1.1.5)\n",
      "Requirement already satisfied: seaborn in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (0.12.1)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (1.0.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from seaborn) (3.5.3)\n",
      "Requirement already satisfied: typing_extensions in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from seaborn) (4.2.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from scikit-learn) (1.7.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/hokuma/Library/Python/3.7/lib/python/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/hokuma/Library/Python/3.7/lib/python/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.3.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.38.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy pandas seaborn scikit-learn seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_SRC='./Data/Trainset/Trainset.csv'\n",
    "TEST_DATA_SRC='./Data/Testset/Testset.csv'\n",
    "train_df=pd.read_csv(TRAIN_DATA_SRC)\n",
    "test_df=pd.read_csv(TEST_DATA_SRC)\n",
    "\n",
    "features=['Possesion','Shots_on_target','Shots','Touches','Passes','Tackles','Clearance','Corners','Offsides','Yellow_cards','Fouls_conceded','Red_cards']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess trainset & testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_features=[features for features in list(train_df) if 'home' in features and 'team' not in features and 'Score' not in features]\n",
    "away_features=[features for features in list(train_df) if 'away' in features and 'team' not in features and 'Score' not in features]\n",
    "\n",
    "winning_train_df=pd.DataFrame(columns=features)\n",
    "losing_train_df=pd.DataFrame(columns=features)\n",
    "winning_test_df=pd.DataFrame(columns=features)\n",
    "losing_test_df=pd.DataFrame(columns=features)\n",
    "\n",
    "for i,row in train_df.iterrows():\n",
    "    if row[3]>row[4]:\n",
    "        winning_train_df.loc[i]=list(row[home_features])\n",
    "        losing_train_df.loc[i]=list(row[away_features])\n",
    "    elif row[4]>row[3]:\n",
    "        winning_train_df.loc[i]=list(row[away_features])\n",
    "        losing_train_df.loc[i]=list(row[home_features])\n",
    "\n",
    "for i,row in test_df.iterrows():\n",
    "    if row[3]>row[4]:\n",
    "        winning_test_df.loc[i]=list(row[home_features])\n",
    "        losing_test_df.loc[i]=list(row[away_features])\n",
    "    elif row[4]>row[3]:\n",
    "        winning_test_df.loc[i]=list(row[away_features])\n",
    "        losing_test_df.loc[i]=list(row[home_features])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.05861052 1.35979163 1.19311343 1.07502493 0.97270886 0.9155342\n",
      " 0.74296156 0.68236642 0.60193765 0.26418056 0.11750118]\n"
     ]
    }
   ],
   "source": [
    "pca=PCA(n_components='mle')\n",
    "scaler=StandardScaler()\n",
    "standardized_winning_train_df=pd.DataFrame(scaler.fit_transform(winning_train_df),columns=features)\n",
    "pca_winning_train_df=pca.fit_transform(standardized_winning_train_df)\n",
    "pov=pca.explained_variance_\n",
    "print(pov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8609793710708921\n"
     ]
    }
   ],
   "source": [
    "print(sum(pov[:7])/sum(pov))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_components가 앞 6개의 feature까지는 설명력이 .9 이상이지만 7번째부터 확연히 줄어들기 때문에 PoV가 .86이더라도 feature를 줄이는 것이 나을 것이라고 판단. \n",
    "n_components는 6으로 진행."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca=PCA(n_components=6)\n",
    "pca_winning_train_df=pd.DataFrame(pca.fit_transform(standardized_winning_train_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "근데 어떤 feature가 설명력이 높은지 알아야 앞으로 test에서 사용할 수 있음.\n",
    "아니면 testset을 2007-2022 data를 전부 합쳐서 pca를 진행하고 split_train_test 함수로 쪼개야함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train_df.drop(columns=['MatchID','Home_team','Away_team','Score_home','Score_away']).values\n",
    "y_train=train_df['Score_home'].values\n",
    "\n",
    "X_test=test_df.drop(columns=['MatchID','Home_team','Away_team','Score_home','Score_away']).values\n",
    "y_test=test_df['Score_home'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  1.69044908117839\n"
     ]
    }
   ],
   "source": [
    "lin_reg=LinearRegression()\n",
    "lin_reg.fit(X_train,y_train)\n",
    "predictions=lin_reg.predict(X_test)\n",
    "lin_mse=mean_squared_error(y_test,predictions)\n",
    "lin_rmse=np.sqrt(lin_mse)\n",
    "print(\"RMSE: \",lin_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset이 늘어나서 RMSE가 1이하로 내려갔지만 여전히 큼..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e774977668b7c0ae8309835a5187aa7fbf7669e7d0bb59755bc63e573643edcd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
