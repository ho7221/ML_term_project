{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classification\n",
    "When importing dataset, by sorting with MatchID, dataset is now timeseries dataset. Every feature is (home-away) and result is decided with score diff. We have total 50 *STANDARDIZED* feature differences. This data frame is for classification."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('Data/Dataset.csv').drop(['Unnamed: 0'],axis=1).sort_values(by=['MatchID'])\n",
    "df_home=data.filter(regex='home').rename(columns=lambda x:x.replace('_home',''))\n",
    "df_away=data.filter(regex='away').rename(columns=lambda x:x.replace('_away',''))\n",
    "df_diff=df_home-df_away\n",
    "cond=[(df_diff['Score']<0),(df_diff['Score']==0),(df_diff['Score']>0)]\n",
    "val=['Away','Draw','Home']\n",
    "df_diff['Result']=np.select(cond,val)\n",
    "df_diff=df_diff.drop(columns=['Score'])\n",
    "X=df_diff.iloc[:,:-1]\n",
    "y=df_diff.iloc[:,-1:].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train,Test,Validation set split\n",
    "Split train,test,validation set into 0.8,0.1,0.1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X_scaled,y,test_size=0.2)\n",
    "X_test,X_val,y_test,y_val=train_test_split(X_test,y_test,test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "((2835, 50), (2835,), (354, 50), (354,), (355, 50), (355,))"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape, X_val.shape, y_val.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SVM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 7, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.5541446208112875\n",
      "test score:0.5621468926553672\n",
      "val score:0.5774647887323944\n"
     ]
    }
   ],
   "source": [
    "parameters = {'kernel': ('linear', 'rbf'), 'gamma': [1, 0.1, 0.01, 0.001, 0.0001], 'C': np.arange(1, 10)}\n",
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svc, parameters)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_params_)\n",
    "print(clf.best_score_)\n",
    "print(\"test score:\"+ str(clf.score(X_test,y_test)))\n",
    "print(\"val score:\"+str(clf.score(X_val,y_val)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "SVM_result=clf.cv_results_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "tmp_score=pd.DataFrame(SVM_result['mean_test_score'])\n",
    "tmp_attr=pd.DataFrame(SVM_result['params'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "SVM_score=pd.concat([tmp_score,tmp_attr],axis=1)\n",
    "SVM_score.columns=['Score','C','gamma','kernel']\n",
    "SVM_score=SVM_score.sort_values(by='Score',ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "       Score  C   gamma kernel\n69  0.554145  7  0.0001    rbf\n59  0.553792  6  0.0001    rbf\n79  0.553086  8  0.0001    rbf\n49  0.552381  5  0.0001    rbf\n39  0.552028  4  0.0001    rbf\n..       ... ..     ...    ...\n81  0.450441  9  1.0000    rbf\n61  0.450441  7  1.0000    rbf\n21  0.450441  3  1.0000    rbf\n71  0.450441  8  1.0000    rbf\n11  0.450441  2  1.0000    rbf\n\n[90 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Score</th>\n      <th>C</th>\n      <th>gamma</th>\n      <th>kernel</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>69</th>\n      <td>0.554145</td>\n      <td>7</td>\n      <td>0.0001</td>\n      <td>rbf</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>0.553792</td>\n      <td>6</td>\n      <td>0.0001</td>\n      <td>rbf</td>\n    </tr>\n    <tr>\n      <th>79</th>\n      <td>0.553086</td>\n      <td>8</td>\n      <td>0.0001</td>\n      <td>rbf</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>0.552381</td>\n      <td>5</td>\n      <td>0.0001</td>\n      <td>rbf</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>0.552028</td>\n      <td>4</td>\n      <td>0.0001</td>\n      <td>rbf</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>81</th>\n      <td>0.450441</td>\n      <td>9</td>\n      <td>1.0000</td>\n      <td>rbf</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>0.450441</td>\n      <td>7</td>\n      <td>1.0000</td>\n      <td>rbf</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0.450441</td>\n      <td>3</td>\n      <td>1.0000</td>\n      <td>rbf</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>0.450441</td>\n      <td>8</td>\n      <td>1.0000</td>\n      <td>rbf</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.450441</td>\n      <td>2</td>\n      <td>1.0000</td>\n      <td>rbf</td>\n    </tr>\n  </tbody>\n</table>\n<p>90 rows Ã— 4 columns</p>\n</div>"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM_score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "more refine with fixed kernel"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 7, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.5541446208112875\n",
      "test score:0.5621468926553672\n",
      "val score:0.5774647887323944\n"
     ]
    }
   ],
   "source": [
    "parameters = {'kernel': ['rbf'], 'gamma': [0.0001,0.00001,0.000001], 'C': np.arange(1, 10)}\n",
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svc, parameters)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_params_)\n",
    "print(clf.best_score_)\n",
    "print(\"test score:\"+ str(clf.score(X_test,y_test)))\n",
    "print(\"val score:\"+str(clf.score(X_val,y_val)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### optimal parameter for SVM classifier\n",
    "> 'C': 7, 'gamma': 0.0001, 'kernel': 'rbf'\n",
    "\n",
    "test score:0.56\n",
    "val score:0.57"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SGD classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 'hinge', 'max_iter': 2500}\n",
      "0.5178130511463845\n",
      "test score:0.5084745762711864\n",
      "val score:0.504225352112676\n"
     ]
    }
   ],
   "source": [
    "parameters = {'loss':['hinge', 'log_loss', 'modified_huber', 'squared_hinge', 'perceptron', 'squared_error', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],'max_iter':[500, 1000, 1500, 2000, 2500, 3000]}\n",
    "svc = SGDClassifier()\n",
    "clf = GridSearchCV(svc, parameters)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_params_)\n",
    "print(clf.best_score_)\n",
    "print(\"test score:\"+ str(clf.score(X_test,y_test)))\n",
    "print(\"val score:\"+str(clf.score(X_val,y_val)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "SGD_result=clf.cv_results_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "{'mean_fit_time': array([0.04657016, 0.04790359, 0.04653454, 0.04534016, 0.05208573,\n        0.04828176, 0.06549859, 0.0649354 , 0.06655421, 0.07005467,\n        0.06573906, 0.06637435, 0.05401974, 0.0549511 , 0.05217109,\n        0.05947337, 0.05278435, 0.05589805, 0.04504905, 0.05192137,\n        0.06072502, 0.05273027, 0.04371166, 0.04225407, 0.04774833,\n        0.04566865, 0.04479065, 0.04643216, 0.04516473, 0.04904084,\n        0.09585299, 0.09775386, 0.10857973, 0.10312271, 0.08956218,\n        0.08989706, 0.03339806, 0.03314543, 0.03145885, 0.03165965,\n        0.03286886, 0.03487067, 0.1069818 , 0.09043384, 0.09237661,\n        0.08668704, 0.08226018, 0.09150434, 0.13087816, 0.12944274,\n        0.1207067 , 0.12655139, 0.13280582, 0.14331365]),\n 'std_fit_time': array([0.00634389, 0.01058731, 0.0081599 , 0.00489757, 0.00861178,\n        0.00340617, 0.00385678, 0.00920806, 0.00482274, 0.01136555,\n        0.00953257, 0.00462567, 0.00722481, 0.00530628, 0.01263617,\n        0.01111073, 0.01119579, 0.00968469, 0.01138832, 0.00860817,\n        0.03316033, 0.01207374, 0.00723005, 0.00961807, 0.00558457,\n        0.00922843, 0.00747433, 0.00690946, 0.00539114, 0.00347335,\n        0.02535809, 0.03460336, 0.03792389, 0.02475223, 0.0047249 ,\n        0.0063958 , 0.00258979, 0.00148433, 0.00118047, 0.00077762,\n        0.00053273, 0.00379417, 0.01813939, 0.00836754, 0.00324364,\n        0.00580589, 0.00969086, 0.01138357, 0.02045521, 0.0201532 ,\n        0.01968067, 0.01263058, 0.01270125, 0.03351155]),\n 'mean_score_time': array([0.0004324 , 0.00039806, 0.0003849 , 0.0004128 , 0.00052586,\n        0.0003932 , 0.00045443, 0.00042195, 0.00047817, 0.00038161,\n        0.00044012, 0.00043797, 0.00043321, 0.00044665, 0.00036612,\n        0.00040512, 0.00035362, 0.00048785, 0.00045986, 0.00042005,\n        0.00079837, 0.00040231, 0.00036206, 0.00034404, 0.00032101,\n        0.00041604, 0.00035176, 0.00036302, 0.00033488, 0.00034199,\n        0.0003808 , 0.00038781, 0.00041451, 0.00043106, 0.00042005,\n        0.00044637, 0.00044723, 0.00045652, 0.00040178, 0.00049582,\n        0.00047345, 0.00041404, 0.00045519, 0.00043364, 0.00044513,\n        0.00041552, 0.00046563, 0.00043025, 0.00039754, 0.00045424,\n        0.00040121, 0.00045242, 0.0004817 , 0.00043015]),\n 'std_score_time': array([1.34343621e-04, 2.27729559e-05, 7.11704977e-05, 3.96731954e-05,\n        1.84873560e-04, 1.76490309e-05, 4.05989809e-05, 2.14074926e-05,\n        8.07460900e-05, 3.63090753e-05, 2.09716213e-05, 5.41330946e-05,\n        5.33348277e-05, 4.20873559e-05, 3.81179341e-05, 5.27823196e-05,\n        3.35289430e-05, 5.05488772e-05, 8.28047187e-05, 2.11515848e-05,\n        7.80857465e-04, 5.20702247e-05, 4.74491549e-05, 1.95799580e-05,\n        1.86409789e-05, 3.68743450e-05, 3.22479439e-05, 3.50066680e-05,\n        3.56017620e-05, 4.66990368e-05, 2.23612733e-05, 4.44392278e-05,\n        3.72814088e-05, 3.64473313e-05, 7.36940065e-05, 5.45759657e-05,\n        3.30841840e-05, 3.92006549e-05, 2.18526723e-05, 5.54915542e-05,\n        3.55668742e-05, 3.32682693e-05, 6.75214549e-05, 3.98675218e-05,\n        6.10867297e-05, 2.22976316e-05, 5.75060473e-05, 2.09116880e-05,\n        2.15008619e-05, 5.93116042e-05, 6.13395729e-05, 2.11549169e-05,\n        8.86980690e-05, 5.36104520e-05]),\n 'param_loss': masked_array(data=['hinge', 'hinge', 'hinge', 'hinge', 'hinge', 'hinge',\n                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n                    'log_loss', 'log_loss', 'modified_huber',\n                    'modified_huber', 'modified_huber', 'modified_huber',\n                    'modified_huber', 'modified_huber', 'squared_hinge',\n                    'squared_hinge', 'squared_hinge', 'squared_hinge',\n                    'squared_hinge', 'squared_hinge', 'perceptron',\n                    'perceptron', 'perceptron', 'perceptron', 'perceptron',\n                    'perceptron', 'squared_error', 'squared_error',\n                    'squared_error', 'squared_error', 'squared_error',\n                    'squared_error', 'huber', 'huber', 'huber', 'huber',\n                    'huber', 'huber', 'epsilon_insensitive',\n                    'epsilon_insensitive', 'epsilon_insensitive',\n                    'epsilon_insensitive', 'epsilon_insensitive',\n                    'epsilon_insensitive', 'squared_epsilon_insensitive',\n                    'squared_epsilon_insensitive',\n                    'squared_epsilon_insensitive',\n                    'squared_epsilon_insensitive',\n                    'squared_epsilon_insensitive',\n                    'squared_epsilon_insensitive'],\n              mask=[False, False, False, False, False, False, False, False,\n                    False, False, False, False, False, False, False, False,\n                    False, False, False, False, False, False, False, False,\n                    False, False, False, False, False, False, False, False,\n                    False, False, False, False, False, False, False, False,\n                    False, False, False, False, False, False, False, False,\n                    False, False, False, False, False, False],\n        fill_value='?',\n             dtype=object),\n 'param_max_iter': masked_array(data=[500, 1000, 1500, 2000, 2500, 3000, 500, 1000, 1500,\n                    2000, 2500, 3000, 500, 1000, 1500, 2000, 2500, 3000,\n                    500, 1000, 1500, 2000, 2500, 3000, 500, 1000, 1500,\n                    2000, 2500, 3000, 500, 1000, 1500, 2000, 2500, 3000,\n                    500, 1000, 1500, 2000, 2500, 3000, 500, 1000, 1500,\n                    2000, 2500, 3000, 500, 1000, 1500, 2000, 2500, 3000],\n              mask=[False, False, False, False, False, False, False, False,\n                    False, False, False, False, False, False, False, False,\n                    False, False, False, False, False, False, False, False,\n                    False, False, False, False, False, False, False, False,\n                    False, False, False, False, False, False, False, False,\n                    False, False, False, False, False, False, False, False,\n                    False, False, False, False, False, False],\n        fill_value='?',\n             dtype=object),\n 'params': [{'loss': 'hinge', 'max_iter': 500},\n  {'loss': 'hinge', 'max_iter': 1000},\n  {'loss': 'hinge', 'max_iter': 1500},\n  {'loss': 'hinge', 'max_iter': 2000},\n  {'loss': 'hinge', 'max_iter': 2500},\n  {'loss': 'hinge', 'max_iter': 3000},\n  {'loss': 'log_loss', 'max_iter': 500},\n  {'loss': 'log_loss', 'max_iter': 1000},\n  {'loss': 'log_loss', 'max_iter': 1500},\n  {'loss': 'log_loss', 'max_iter': 2000},\n  {'loss': 'log_loss', 'max_iter': 2500},\n  {'loss': 'log_loss', 'max_iter': 3000},\n  {'loss': 'modified_huber', 'max_iter': 500},\n  {'loss': 'modified_huber', 'max_iter': 1000},\n  {'loss': 'modified_huber', 'max_iter': 1500},\n  {'loss': 'modified_huber', 'max_iter': 2000},\n  {'loss': 'modified_huber', 'max_iter': 2500},\n  {'loss': 'modified_huber', 'max_iter': 3000},\n  {'loss': 'squared_hinge', 'max_iter': 500},\n  {'loss': 'squared_hinge', 'max_iter': 1000},\n  {'loss': 'squared_hinge', 'max_iter': 1500},\n  {'loss': 'squared_hinge', 'max_iter': 2000},\n  {'loss': 'squared_hinge', 'max_iter': 2500},\n  {'loss': 'squared_hinge', 'max_iter': 3000},\n  {'loss': 'perceptron', 'max_iter': 500},\n  {'loss': 'perceptron', 'max_iter': 1000},\n  {'loss': 'perceptron', 'max_iter': 1500},\n  {'loss': 'perceptron', 'max_iter': 2000},\n  {'loss': 'perceptron', 'max_iter': 2500},\n  {'loss': 'perceptron', 'max_iter': 3000},\n  {'loss': 'squared_error', 'max_iter': 500},\n  {'loss': 'squared_error', 'max_iter': 1000},\n  {'loss': 'squared_error', 'max_iter': 1500},\n  {'loss': 'squared_error', 'max_iter': 2000},\n  {'loss': 'squared_error', 'max_iter': 2500},\n  {'loss': 'squared_error', 'max_iter': 3000},\n  {'loss': 'huber', 'max_iter': 500},\n  {'loss': 'huber', 'max_iter': 1000},\n  {'loss': 'huber', 'max_iter': 1500},\n  {'loss': 'huber', 'max_iter': 2000},\n  {'loss': 'huber', 'max_iter': 2500},\n  {'loss': 'huber', 'max_iter': 3000},\n  {'loss': 'epsilon_insensitive', 'max_iter': 500},\n  {'loss': 'epsilon_insensitive', 'max_iter': 1000},\n  {'loss': 'epsilon_insensitive', 'max_iter': 1500},\n  {'loss': 'epsilon_insensitive', 'max_iter': 2000},\n  {'loss': 'epsilon_insensitive', 'max_iter': 2500},\n  {'loss': 'epsilon_insensitive', 'max_iter': 3000},\n  {'loss': 'squared_epsilon_insensitive', 'max_iter': 500},\n  {'loss': 'squared_epsilon_insensitive', 'max_iter': 1000},\n  {'loss': 'squared_epsilon_insensitive', 'max_iter': 1500},\n  {'loss': 'squared_epsilon_insensitive', 'max_iter': 2000},\n  {'loss': 'squared_epsilon_insensitive', 'max_iter': 2500},\n  {'loss': 'squared_epsilon_insensitive', 'max_iter': 3000}],\n 'split0_test_score': array([0.49206349, 0.4356261 , 0.47089947, 0.44973545, 0.4691358 ,\n        0.45326279, 0.50440917, 0.43209877, 0.44444444, 0.44620811,\n        0.44620811, 0.43386243, 0.43209877, 0.47795414, 0.41798942,\n        0.44973545, 0.43738977, 0.42857143, 0.47089947, 0.4303351 ,\n        0.42857143, 0.42328042, 0.51146384, 0.4356261 , 0.41622575,\n        0.42680776, 0.33156966, 0.46560847, 0.47795414, 0.42151675,\n        0.32275132, 0.38624339, 0.34038801, 0.3633157 , 0.32098765,\n        0.35626102, 0.46737213, 0.48500882, 0.43738977, 0.50088183,\n        0.47971781, 0.51146384, 0.41446208, 0.38977072, 0.45326279,\n        0.44268078, 0.48148148, 0.38271605, 0.28218695, 0.33156966,\n        0.35626102, 0.35449735, 0.28395062, 0.31746032]),\n 'split1_test_score': array([0.5026455 , 0.48853616, 0.4691358 , 0.50088183, 0.52380952,\n        0.50970018, 0.47442681, 0.49206349, 0.48500882, 0.5026455 ,\n        0.51851852, 0.49029982, 0.43738977, 0.44797178, 0.41622575,\n        0.49382716, 0.48324515, 0.41269841, 0.48853616, 0.4356261 ,\n        0.48324515, 0.45679012, 0.40740741, 0.50088183, 0.46560847,\n        0.40388007, 0.49206349, 0.44973545, 0.50793651, 0.49382716,\n        0.35802469, 0.33333333, 0.28747795, 0.329806  , 0.28395062,\n        0.38447972, 0.51851852, 0.48148148, 0.50793651, 0.52380952,\n        0.51499118, 0.44797178, 0.39153439, 0.41093474, 0.46208113,\n        0.32098765, 0.43738977, 0.34567901, 0.29453263, 0.3015873 ,\n        0.29982363, 0.28395062, 0.3968254 , 0.28924162]),\n 'split2_test_score': array([0.49029982, 0.51675485, 0.52204586, 0.53262787, 0.52557319,\n        0.48324515, 0.49382716, 0.46031746, 0.46560847, 0.52910053,\n        0.50440917, 0.49559083, 0.4638448 , 0.51851852, 0.48677249,\n        0.54320988, 0.50793651, 0.42680776, 0.42504409, 0.44797178,\n        0.4356261 , 0.50440917, 0.41975309, 0.44444444, 0.40035273,\n        0.43915344, 0.5361552 , 0.47442681, 0.49559083, 0.41446208,\n        0.43738977, 0.3686067 , 0.31040564, 0.3968254 , 0.47442681,\n        0.34215168, 0.47795414, 0.52733686, 0.54497354, 0.42328042,\n        0.50440917, 0.50088183, 0.3686067 , 0.43386243, 0.35449735,\n        0.49382716, 0.3633157 , 0.41798942, 0.29100529, 0.31393298,\n        0.31569665, 0.45855379, 0.29453263, 0.38977072]),\n 'split3_test_score': array([0.51499118, 0.46560847, 0.53791887, 0.50088183, 0.53791887,\n        0.50617284, 0.53439153, 0.50617284, 0.55908289, 0.47795414,\n        0.51851852, 0.47442681, 0.43738977, 0.47266314, 0.45326279,\n        0.41093474, 0.49559083, 0.45326279, 0.3968254 , 0.42328042,\n        0.4691358 , 0.44268078, 0.43386243, 0.4303351 , 0.5361552 ,\n        0.48853616, 0.49206349, 0.49206349, 0.52557319, 0.45502646,\n        0.34391534, 0.50617284, 0.42328042, 0.33862434, 0.28042328,\n        0.39329806, 0.55379189, 0.48500882, 0.47619048, 0.4973545 ,\n        0.5026455 , 0.4638448 , 0.48677249, 0.49029982, 0.44620811,\n        0.49029982, 0.42680776, 0.27513228, 0.47089947, 0.28395062,\n        0.3015873 , 0.41446208, 0.30864198, 0.38271605]),\n 'split4_test_score': array([0.48853616, 0.40564374, 0.5026455 , 0.41975309, 0.53262787,\n        0.47619048, 0.52380952, 0.50793651, 0.51146384, 0.49029982,\n        0.51322751, 0.4638448 , 0.40564374, 0.51146384, 0.44268078,\n        0.41975309, 0.46208113, 0.50440917, 0.47619048, 0.48324515,\n        0.37742504, 0.4691358 , 0.45679012, 0.45326279, 0.41093474,\n        0.35273369, 0.45855379, 0.46208113, 0.34038801, 0.44444444,\n        0.34215168, 0.36684303, 0.2680776 , 0.29453263, 0.28395062,\n        0.48677249, 0.48324515, 0.53968254, 0.51322751, 0.42680776,\n        0.48148148, 0.49382716, 0.34744268, 0.43738977, 0.41269841,\n        0.3633157 , 0.46208113, 0.45326279, 0.28571429, 0.38095238,\n        0.27513228, 0.38095238, 0.32627866, 0.30335097]),\n 'mean_test_score': array([0.49770723, 0.46243386, 0.5005291 , 0.48077601, 0.51781305,\n        0.48571429, 0.50617284, 0.47971781, 0.49312169, 0.48924162,\n        0.50017637, 0.47160494, 0.43527337, 0.48571429, 0.44338624,\n        0.46349206, 0.47724868, 0.44514991, 0.45149912, 0.44409171,\n        0.43880071, 0.45925926, 0.44585538, 0.45291005, 0.44585538,\n        0.42222222, 0.46208113, 0.46878307, 0.46948854, 0.44585538,\n        0.36084656, 0.39223986, 0.32592593, 0.34462081, 0.3287478 ,\n        0.39259259, 0.50017637, 0.5037037 , 0.49594356, 0.47442681,\n        0.49664903, 0.48359788, 0.40176367, 0.4324515 , 0.42574956,\n        0.42222222, 0.43421517, 0.37495591, 0.32486772, 0.32239859,\n        0.30970018, 0.37848325, 0.32204586, 0.33650794]),\n 'std_test_score': array([0.00993933, 0.03895113, 0.02730897, 0.04045842, 0.02485709,\n        0.0207064 , 0.02131049, 0.02930026, 0.03969782, 0.02738177,\n        0.0274725 , 0.02198864, 0.01851096, 0.02605458, 0.02593492,\n        0.04927426, 0.02503167, 0.03237857, 0.03477604, 0.02117578,\n        0.03681634, 0.02724511, 0.03668091, 0.02522477, 0.05042241,\n        0.04443044, 0.06975749, 0.01408287, 0.06639831, 0.02816132,\n        0.03988543, 0.0594814 , 0.0543187 , 0.03417332, 0.07433899,\n        0.05059731, 0.03183605, 0.02468128, 0.03651092, 0.04134665,\n        0.01377921, 0.02382976, 0.04804694, 0.03363755, 0.03935155,\n        0.0691358 , 0.04025494, 0.06142632, 0.07313931, 0.03315321,\n        0.02669148, 0.05869175, 0.03999446, 0.04163752]),\n 'rank_test_score': array([ 7, 23,  4, 15,  1, 12,  2, 16, 10, 11,  5, 19, 35, 13, 33, 22, 17,\n        31, 27, 32, 34, 25, 28, 26, 28, 40, 24, 21, 20, 28, 46, 43, 50, 47,\n        49, 42,  6,  3,  9, 18,  8, 14, 41, 37, 38, 39, 36, 45, 51, 52, 54,\n        44, 53, 48], dtype=int32)}"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGD_result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "tmp_score=pd.DataFrame(SGD_result['mean_test_score'])\n",
    "tmp_attr=pd.DataFrame(SGD_result['params'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "SGD_score=pd.concat([tmp_score,tmp_attr],axis=1)\n",
    "SGD_score.columns=['Score','loss','max_iter']\n",
    "SGD_score=SGD_score.sort_values(by='Score',ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "       Score                         loss  max_iter\n4   0.517813                        hinge      2500\n6   0.506173                     log_loss       500\n37  0.503704                        huber      1000\n2   0.500529                        hinge      1500\n10  0.500176                     log_loss      2500\n36  0.500176                        huber       500\n0   0.497707                        hinge       500\n40  0.496649                        huber      2500\n38  0.495944                        huber      1500\n8   0.493122                     log_loss      1500\n9   0.489242                     log_loss      2000\n5   0.485714                        hinge      3000\n13  0.485714               modified_huber      1000\n41  0.483598                        huber      3000\n3   0.480776                        hinge      2000\n7   0.479718                     log_loss      1000\n16  0.477249               modified_huber      2500\n39  0.474427                        huber      2000\n11  0.471605                     log_loss      3000\n28  0.469489                   perceptron      2500\n27  0.468783                   perceptron      2000\n15  0.463492               modified_huber      2000\n1   0.462434                        hinge      1000\n26  0.462081                   perceptron      1500\n21  0.459259                squared_hinge      2000\n23  0.452910                squared_hinge      3000\n18  0.451499                squared_hinge       500\n24  0.445855                   perceptron       500\n29  0.445855                   perceptron      3000\n22  0.445855                squared_hinge      2500\n17  0.445150               modified_huber      3000\n19  0.444092                squared_hinge      1000\n14  0.443386               modified_huber      1500\n20  0.438801                squared_hinge      1500\n12  0.435273               modified_huber       500\n46  0.434215          epsilon_insensitive      2500\n43  0.432451          epsilon_insensitive      1000\n44  0.425750          epsilon_insensitive      1500\n45  0.422222          epsilon_insensitive      2000\n25  0.422222                   perceptron      1000\n42  0.401764          epsilon_insensitive       500\n35  0.392593                squared_error      3000\n31  0.392240                squared_error      1000\n51  0.378483  squared_epsilon_insensitive      2000\n47  0.374956          epsilon_insensitive      3000\n30  0.360847                squared_error       500\n33  0.344621                squared_error      2000\n53  0.336508  squared_epsilon_insensitive      3000\n34  0.328748                squared_error      2500\n32  0.325926                squared_error      1500\n48  0.324868  squared_epsilon_insensitive       500\n49  0.322399  squared_epsilon_insensitive      1000\n52  0.322046  squared_epsilon_insensitive      2500\n50  0.309700  squared_epsilon_insensitive      1500",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Score</th>\n      <th>loss</th>\n      <th>max_iter</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4</th>\n      <td>0.517813</td>\n      <td>hinge</td>\n      <td>2500</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.506173</td>\n      <td>log_loss</td>\n      <td>500</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>0.503704</td>\n      <td>huber</td>\n      <td>1000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.500529</td>\n      <td>hinge</td>\n      <td>1500</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.500176</td>\n      <td>log_loss</td>\n      <td>2500</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>0.500176</td>\n      <td>huber</td>\n      <td>500</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.497707</td>\n      <td>hinge</td>\n      <td>500</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>0.496649</td>\n      <td>huber</td>\n      <td>2500</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>0.495944</td>\n      <td>huber</td>\n      <td>1500</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.493122</td>\n      <td>log_loss</td>\n      <td>1500</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.489242</td>\n      <td>log_loss</td>\n      <td>2000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.485714</td>\n      <td>hinge</td>\n      <td>3000</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.485714</td>\n      <td>modified_huber</td>\n      <td>1000</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>0.483598</td>\n      <td>huber</td>\n      <td>3000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.480776</td>\n      <td>hinge</td>\n      <td>2000</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.479718</td>\n      <td>log_loss</td>\n      <td>1000</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0.477249</td>\n      <td>modified_huber</td>\n      <td>2500</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>0.474427</td>\n      <td>huber</td>\n      <td>2000</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.471605</td>\n      <td>log_loss</td>\n      <td>3000</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>0.469489</td>\n      <td>perceptron</td>\n      <td>2500</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>0.468783</td>\n      <td>perceptron</td>\n      <td>2000</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0.463492</td>\n      <td>modified_huber</td>\n      <td>2000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.462434</td>\n      <td>hinge</td>\n      <td>1000</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>0.462081</td>\n      <td>perceptron</td>\n      <td>1500</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0.459259</td>\n      <td>squared_hinge</td>\n      <td>2000</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>0.452910</td>\n      <td>squared_hinge</td>\n      <td>3000</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0.451499</td>\n      <td>squared_hinge</td>\n      <td>500</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>0.445855</td>\n      <td>perceptron</td>\n      <td>500</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>0.445855</td>\n      <td>perceptron</td>\n      <td>3000</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>0.445855</td>\n      <td>squared_hinge</td>\n      <td>2500</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0.445150</td>\n      <td>modified_huber</td>\n      <td>3000</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0.444092</td>\n      <td>squared_hinge</td>\n      <td>1000</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.443386</td>\n      <td>modified_huber</td>\n      <td>1500</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>0.438801</td>\n      <td>squared_hinge</td>\n      <td>1500</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.435273</td>\n      <td>modified_huber</td>\n      <td>500</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>0.434215</td>\n      <td>epsilon_insensitive</td>\n      <td>2500</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>0.432451</td>\n      <td>epsilon_insensitive</td>\n      <td>1000</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>0.425750</td>\n      <td>epsilon_insensitive</td>\n      <td>1500</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>0.422222</td>\n      <td>epsilon_insensitive</td>\n      <td>2000</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>0.422222</td>\n      <td>perceptron</td>\n      <td>1000</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>0.401764</td>\n      <td>epsilon_insensitive</td>\n      <td>500</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>0.392593</td>\n      <td>squared_error</td>\n      <td>3000</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>0.392240</td>\n      <td>squared_error</td>\n      <td>1000</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>0.378483</td>\n      <td>squared_epsilon_insensitive</td>\n      <td>2000</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>0.374956</td>\n      <td>epsilon_insensitive</td>\n      <td>3000</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>0.360847</td>\n      <td>squared_error</td>\n      <td>500</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>0.344621</td>\n      <td>squared_error</td>\n      <td>2000</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>0.336508</td>\n      <td>squared_epsilon_insensitive</td>\n      <td>3000</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>0.328748</td>\n      <td>squared_error</td>\n      <td>2500</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>0.325926</td>\n      <td>squared_error</td>\n      <td>1500</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>0.324868</td>\n      <td>squared_epsilon_insensitive</td>\n      <td>500</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>0.322399</td>\n      <td>squared_epsilon_insensitive</td>\n      <td>1000</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>0.322046</td>\n      <td>squared_epsilon_insensitive</td>\n      <td>2500</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>0.309700</td>\n      <td>squared_epsilon_insensitive</td>\n      <td>1500</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGD_score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "more refine with fixed loss function(hinge)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 'hinge', 'max_iter': 2000, 'random_state': 5}\n",
      "0.508994708994709\n",
      "test score:0.5338983050847458\n",
      "val score:0.5774647887323944\n"
     ]
    }
   ],
   "source": [
    "parameters = {'loss':['hinge'],'max_iter':np.arange(2000,6000,step=500),'random_state':np.arange(0,10)}\n",
    "svc = SGDClassifier()\n",
    "clf = GridSearchCV(svc, parameters)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_params_)\n",
    "print(clf.best_score_)\n",
    "print(\"test score:\"+ str(clf.score(X_test,y_test)))\n",
    "print(\"val score:\"+str(clf.score(X_val,y_val)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### optimal parameter for SGD classifier\n",
    "> 'loss': 'hinge', 'max_iter': 2000\n",
    "\n",
    "test score:0.53\n",
    "val score:0.57"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Decision Tree"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'random_state': 7}\n",
      "0.5174603174603174\n",
      "test score:0.5508474576271186\n",
      "val score:0.543661971830986\n"
     ]
    },
    {
     "data": {
      "text/plain": "DecisionTreeClassifier()",
      "text/html": "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'random_state':np.arange(0,10)}\n",
    "svc = SGDClassifier()\n",
    "clf = GridSearchCV(svc, parameters)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_params_)\n",
    "print(clf.best_score_)\n",
    "print(\"test score:\"+ str(clf.score(X_test,y_test)))\n",
    "print(\"val score:\"+str(clf.score(X_val,y_val)))\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(X_train,y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### visualize decision tree"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "export_graphviz(clf, out_file=\"tree.dot\", class_names = y_train,\n",
    "                feature_names = X.columns, impurity=True, filled=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'graphviz'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [15], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mgraphviz\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtree.dot\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[1;32m      3\u001B[0m  dot_graph \u001B[38;5;241m=\u001B[39m f\u001B[38;5;241m.\u001B[39mread()\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'graphviz'"
     ]
    }
   ],
   "source": [
    "import graphviz\n",
    "with open(\"tree.dot\") as f:\n",
    " dot_graph = f.read()\n",
    "graphviz.Source(dot_graph)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "LogisticRegression(max_iter=500)",
      "text/html": "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=500)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=500)</pre></div></div></div></div></div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters={'max_iter':[500, 1000, 1500, 2000, 2500, 3000]}\n",
    " = LogisticRegression()\n",
    "clf.max_iter=500\n",
    "clf.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "0.519774011299435"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test,y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "0.5492957746478874"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_val,y_val)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e774977668b7c0ae8309835a5187aa7fbf7669e7d0bb59755bc63e573643edcd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
